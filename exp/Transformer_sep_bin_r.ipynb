{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna rtdl category_encoders ruamel.yaml einops"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:38:09.630898Z",
          "iopub.execute_input": "2023-04-18T20:38:09.631886Z",
          "iopub.status.idle": "2023-04-18T20:38:25.299235Z",
          "shell.execute_reply.started": "2023-04-18T20:38:09.631830Z",
          "shell.execute_reply": "2023-04-18T20:38:25.297910Z"
        },
        "trusted": true,
        "id": "WRTTiC0otM73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import fmin\n",
        "import random\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import pathlib\n",
        "import argparse\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.checkpoint as cp\n",
        "from tqdm import tqdm, trange\n",
        "from typing import Optional, Sequence, Tuple, Union, Any, Dict, List\n",
        "from copy import deepcopy\n",
        "import enum\n",
        "import optuna\n",
        "import rtdl\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "import category_encoders as ce\n",
        "import ruamel.yaml\n",
        "import math\n",
        "from collections import OrderedDict, defaultdict\n",
        "from sklearn.metrics import roc_auc_score, f1_score, precision_score, accuracy_score, recall_score, roc_auc_score, balanced_accuracy_score, log_loss, mean_absolute_error, mean_squared_error, r2_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from scipy.spatial import distance_matrix\n",
        "from scipy.linalg import qr\n",
        "import enum\n",
        "from einops import rearrange\n",
        "from torch import nn, einsum\n",
        "from einops import rearrange"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:38:34.790653Z",
          "iopub.execute_input": "2023-04-18T20:38:34.791095Z",
          "iopub.status.idle": "2023-04-18T20:38:38.497506Z",
          "shell.execute_reply.started": "2023-04-18T20:38:34.791052Z",
          "shell.execute_reply": "2023-04-18T20:38:38.496505Z"
        },
        "trusted": true,
        "id": "A6Y-rpM3tM74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_global_seed(seed: int) -> None:\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "set_global_seed(42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:38:38.500375Z",
          "iopub.execute_input": "2023-04-18T20:38:38.501246Z",
          "iopub.status.idle": "2023-04-18T20:38:38.510654Z",
          "shell.execute_reply.started": "2023-04-18T20:38:38.501205Z",
          "shell.execute_reply": "2023-04-18T20:38:38.509387Z"
        },
        "trusted": true,
        "id": "1Lj3zyaXtM75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:38:38.512523Z",
          "iopub.execute_input": "2023-04-18T20:38:38.512960Z",
          "iopub.status.idle": "2023-04-18T20:38:38.600978Z",
          "shell.execute_reply.started": "2023-04-18T20:38:38.512923Z",
          "shell.execute_reply": "2023-04-18T20:38:38.599911Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KcTs_baHtM76",
        "outputId": "32f46962-f528-42bb-ddd0-b69a14283302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessings"
      ],
      "metadata": {
        "id": "NrA62aWDtM77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Function\n",
        "\n",
        "def cos_sin(x: torch.Tensor) -> torch.Tensor:\n",
        "    return torch.cat([torch.cos(x), torch.sin(x)], -1)\n",
        "\n",
        "def positional(d, pos):\n",
        "    return torch.Tensor([np.sin(1/10000 ** (2 * int(i / 2) / d) * pos) if i % 2 == 0 else \n",
        "                       np.cos(1/10000 ** (2 * int(i / 2) / d) * pos) for i in range(d)])\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, n_features: int = 5000, dropout: float = 0.1, tf: bool=False):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.tf = tf\n",
        "        self.d_model = d_model\n",
        "        position = torch.arange(n_features).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(n_features, d_model)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "        self.pe = pe\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        if self.tf:\n",
        "            x = x + self.pe.unsqueeze(0)\n",
        "        else:\n",
        "            x = x + self.pe.view(1, -1)\n",
        "        return self.dropout(x)\n",
        "    \n",
        "class Periodic(nn.Module):\n",
        "    def __init__(self, n_features: int, n: int, sigma: float, trainable: bool, initialization: str, tf: bool) -> None:\n",
        "        super().__init__()\n",
        "        self.tf = tf\n",
        "        if initialization == 'log-linear':\n",
        "            coefficients = sigma ** (torch.arange(n) / n)\n",
        "            coefficients = coefficients[None].repeat(n_features, 1)\n",
        "        else:\n",
        "            assert initialization == 'normal'\n",
        "            coefficients = torch.normal(0.0, sigma, (n_features, n))\n",
        "        if trainable:\n",
        "            self.coefficients = nn.Parameter(coefficients)  \n",
        "        else:\n",
        "            self.register_buffer('coefficients', coefficients)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        if not self.tf:\n",
        "            return cos_sin(2 * np.pi * self.coefficients[None] * x[..., None]).view(-1, 2 * x.shape[1] * self.coefficients.shape[1])\n",
        "        else:\n",
        "            return cos_sin(2 * np.pi * self.coefficients[None] * x[..., None]).view(x.shape[0], x.shape[1], 2 * self.coefficients.shape[1])\n",
        "    \n",
        "    \n",
        "class NLinear(nn.Module):\n",
        "    def __init__(self, n: int, d_in: int, d_out: int, bias: bool = True) -> None:\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.Tensor(n, d_in, d_out))\n",
        "        self.bias = nn.Parameter(torch.Tensor(n, d_out)) if bias else None\n",
        "        with torch.no_grad():\n",
        "            for i in range(n):\n",
        "                layer = nn.Linear(d_in, d_out)\n",
        "                self.weight[i] = layer.weight.T\n",
        "                if self.bias is not None:\n",
        "                    self.bias[i] = layer.bias\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.ndim == 3:\n",
        "            x = x[..., None] * self.weight[None]\n",
        "            x = x.sum(-2)\n",
        "            if self.bias is not None:\n",
        "                x = x + self.bias[None]\n",
        "            return x\n",
        "    \n",
        "\n",
        "class FeaturesTokenizer(nn.Module):\n",
        "    def __init__(self, n_features: int, d_embedding: int, tf: bool) -> None:\n",
        "        super().__init__()\n",
        "        self.tf = tf\n",
        "        self.first_layer = rtdl.NumericalFeatureTokenizer(n_features, d_embedding, True, 'uniform')\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.first_layer(x)\n",
        "        if not self.tf:\n",
        "            return x.view(x.shape[0], -1)\n",
        "        else:\n",
        "            return x\n",
        "    \n",
        "class LinearEmbeddings(nn.Module):\n",
        "    def __init__(self, n_layers, n_features, d_embeddings, tf):\n",
        "        super().__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.tf = tf\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i in range(n_layers):\n",
        "            if i == 0:\n",
        "                self.layers.append(rtdl.NumericalFeatureTokenizer(n_features, d_embeddings[i], False, 'uniform'))\n",
        "            else:\n",
        "                self.layers.append(NLinear(n_features, d_embeddings[i-1], d_embeddings[i], False))\n",
        "        self.leaky_relu = nn.LeakyReLU()\n",
        "        \n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        for i in range(self.n_layers):\n",
        "            x = self.layers[i](x)\n",
        "            x = self.leaky_relu(x)\n",
        "        if not self.tf:\n",
        "            return x.view(x.shape[0], -1)\n",
        "        else:\n",
        "            return x    \n",
        "    \n",
        "    \n",
        "class AutoDis(nn.Module):\n",
        "    def __init__(\n",
        "        self, n_features: int, d_embedding: int, n_meta_embeddings: int, temperature: float, tf: bool\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.first_layer = rtdl.NumericalFeatureTokenizer(\n",
        "            n_features,\n",
        "            n_meta_embeddings,\n",
        "            False,\n",
        "            'uniform',\n",
        "        )\n",
        "        self.tf = tf\n",
        "        self.leaky_relu = nn.LeakyReLU()\n",
        "        self.second_layer = NLinear(\n",
        "            n_features, n_meta_embeddings, n_meta_embeddings, False\n",
        "        )\n",
        "        self.softmax = nn.Softmax(-1)\n",
        "        self.temperature = temperature\n",
        "        self.third_layer = NLinear(\n",
        "            n_features, n_meta_embeddings, d_embedding, False\n",
        "        )\n",
        "        nn.init.uniform_(self.third_layer.weight, 0.01)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.first_layer(x)\n",
        "        x = self.leaky_relu(x)\n",
        "        x = self.second_layer(x)\n",
        "        x = self.softmax(x / self.temperature)\n",
        "        x = self.third_layer(x)\n",
        "        if not self.tf:\n",
        "            return x.view(x.shape[0], -1)\n",
        "        else:\n",
        "            return x\n",
        "    \n",
        "    \n",
        "class SoftEmbedding(torch.nn.Module):\n",
        "    def __init__(self, num_embeddings, embeddings_dim, emb_initializer=None, tf=True):\n",
        "        super(SoftEmbedding, self).__init__()\n",
        "        self.embedding_table = torch.nn.Embedding(num_embeddings, embeddings_dim)\n",
        "        if emb_initializer:\n",
        "            emb_initializer(self.embedding_table.weight)\n",
        "        self.projection_layer = torch.nn.Linear(1, num_embeddings, bias=True)\n",
        "        self.softmax = torch.nn.Softmax(dim=-1)\n",
        "        self.tf = tf\n",
        "\n",
        "    def forward(self, input_numeric):\n",
        "        input_numeric = input_numeric.unsqueeze(-1)\n",
        "        weights = self.softmax(self.projection_layer(input_numeric))\n",
        "        soft_one_hot_embeddings = (weights.unsqueeze(-1) * self.embedding_table.weight).sum(-2)\n",
        "        if not self.tf:\n",
        "            return soft_one_hot_embeddings.view(soft_one_hot_embeddings.shape[0], -1)\n",
        "        else:\n",
        "            return soft_one_hot_embeddings\n",
        "                \n",
        "        \n",
        "class EntmaxBisectFunction(Function):\n",
        "    @classmethod\n",
        "    def _gp(cls, x, alpha):\n",
        "        return x ** (alpha - 1)\n",
        "\n",
        "    @classmethod\n",
        "    def _gp_inv(cls, y, alpha):\n",
        "        return y ** (1 / (alpha - 1))\n",
        "\n",
        "    @classmethod\n",
        "    def _p(cls, X, alpha):\n",
        "        return cls._gp_inv(torch.clamp(X, min=1e-6), alpha)\n",
        "\n",
        "    @classmethod\n",
        "    def forward(cls, ctx, X, alpha=1.5, dim=-1, n_iter=50, ensure_sum_one=True):\n",
        "\n",
        "        if not isinstance(alpha, torch.Tensor):\n",
        "            alpha = torch.tensor(alpha, dtype=X.dtype, device=X.device)\n",
        "\n",
        "        alpha_shape = list(X.shape)\n",
        "        alpha_shape[dim] = 1\n",
        "        alpha = alpha.expand(*alpha_shape)\n",
        "\n",
        "        ctx.alpha = alpha\n",
        "        ctx.dim = dim\n",
        "        d = X.shape[dim]\n",
        "\n",
        "        X = X * (alpha - 1)\n",
        "\n",
        "        max_val, _ = X.max(dim=dim, keepdim=True)\n",
        "\n",
        "        tau_lo = max_val - cls._gp(1, alpha)\n",
        "        tau_hi = max_val - cls._gp(1 / d, alpha)\n",
        "\n",
        "        f_lo = cls._p(X - tau_lo, alpha).sum(dim) - 1\n",
        "\n",
        "        dm = tau_hi - tau_lo\n",
        "\n",
        "        for it in range(n_iter):\n",
        "\n",
        "            dm /= 2\n",
        "            tau_m = tau_lo + dm\n",
        "            p_m = cls._p(X - tau_m, alpha)\n",
        "            f_m = p_m.sum(dim) - 1\n",
        "\n",
        "            mask = (f_m * f_lo >= 0).unsqueeze(dim)\n",
        "            tau_lo = torch.where(mask, tau_m, tau_lo)\n",
        "\n",
        "        if ensure_sum_one:\n",
        "            p_m /= p_m.sum(dim=dim).unsqueeze(dim=dim)\n",
        "\n",
        "        ctx.save_for_backward(p_m)\n",
        "\n",
        "        return p_m\n",
        "\n",
        "    @classmethod\n",
        "    def backward(cls, ctx, dY):\n",
        "        Y, = ctx.saved_tensors\n",
        "\n",
        "        gppr = torch.where(Y > 0, Y ** (2 - ctx.alpha), Y.new_zeros(1))\n",
        "\n",
        "        dX = dY * gppr\n",
        "        q = dX.sum(ctx.dim) / gppr.sum(ctx.dim)\n",
        "        q = q.unsqueeze(ctx.dim)\n",
        "        dX -= q * gppr\n",
        "\n",
        "        d_alpha = None\n",
        "        if ctx.needs_input_grad[1]:\n",
        "            S = torch.where(Y > 0, Y * torch.log(Y), Y.new_zeros(1))\n",
        "            ent = S.sum(ctx.dim).unsqueeze(ctx.dim)\n",
        "            Y_skewed = gppr / gppr.sum(ctx.dim).unsqueeze(ctx.dim)\n",
        "\n",
        "            d_alpha = dY * (Y - Y_skewed) / ((ctx.alpha - 1) ** 2)\n",
        "            d_alpha -= dY * (S - Y_skewed * ent) / (ctx.alpha - 1)\n",
        "            d_alpha = d_alpha.sum(ctx.dim).unsqueeze(ctx.dim)\n",
        "\n",
        "        return dX, d_alpha, None, None, None\n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "def entmax_bisect(X, alpha=1.5, dim=-1, n_iter=50, ensure_sum_one=True):\n",
        "    return EntmaxBisectFunction.apply(X, alpha, dim, n_iter, ensure_sum_one)\n",
        "\n",
        "        \n",
        "        \n",
        "class EntmaxBisect(nn.Module):\n",
        "    def __init__(self, alpha=1.5, dim=-1, n_iter=50):\n",
        "        self.dim = dim\n",
        "        self.n_iter = n_iter\n",
        "        self.alpha = alpha\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, X):\n",
        "        return entmax_bisect(\n",
        "            X, alpha=self.alpha, dim=self.dim, n_iter=self.n_iter\n",
        "        )\n",
        "  \n",
        "        \n",
        "class SparseAttLayer(nn.Module):\n",
        "    def __init__(self, nhead: int, nfield: int, nemb: int, d_k: int, nhid: int, alpha: float = 1.5):\n",
        "        super(SparseAttLayer, self).__init__()\n",
        "        self.sparsemax = nn.Softmax(dim=-1) if alpha == 1. \\\n",
        "            else EntmaxBisect(alpha, dim=-1)\n",
        "\n",
        "        self.scale = d_k ** -0.5\n",
        "        self.bilinear_w = nn.Parameter(torch.zeros(nhead, nemb, d_k))                   \n",
        "        self.query = nn.Parameter(torch.zeros(nhead, nhid, d_k))                        \n",
        "        self.values = nn.Parameter(torch.zeros(nhead, nhid, nfield))                    \n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self) -> None:\n",
        "        nn.init.xavier_uniform_(self.bilinear_w, gain=1.414)\n",
        "        nn.init.xavier_uniform_(self.query, gain=1.414)\n",
        "        nn.init.xavier_uniform_(self.values, gain=1.414)\n",
        "\n",
        "    def forward(self, x):\n",
        "        keys = x                                                                        \n",
        "        att_gates = torch.einsum('bfx,kxy,koy->bkof',\n",
        "                                 keys, self.bilinear_w, self.query) * self.scale        \n",
        "        sparse_gates = self.sparsemax(att_gates)                                        \n",
        "        return torch.einsum('bkof,kof->bkof', sparse_gates, self.values)\n",
        "\n",
        "    \n",
        "class Embedding(nn.Module):\n",
        "\n",
        "    def __init__(self, nfeat, nemb):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(nfeat, nemb)\n",
        "        nn.init.xavier_uniform_(self.embedding.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x['id'])                           \n",
        "        return emb * x['value'].unsqueeze(2)                    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def exists(val):\n",
        "    return val is not None\n",
        "\n",
        "def default(val, d):\n",
        "    return val if exists(val) else d\n",
        "\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(x, **kwargs) + x\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "class GEGLU(nn.Module):\n",
        "    def forward(self, x):\n",
        "        x, gates = x.chunk(2, dim = -1)\n",
        "        return x * F.gelu(gates)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, mult = 4, dropout = 0.):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, dim * mult * 2),\n",
        "            GEGLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(dim * mult, dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.net(x)\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        heads = 8,\n",
        "        dim_head = 16,\n",
        "        dropout = 0.\n",
        "    ):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * heads\n",
        "        self.heads = heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
        "        self.to_out = nn.Linear(inner_dim, dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.heads\n",
        "        q, k, v = self.to_qkv(x).chunk(3, dim = -1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), (q, k, v))\n",
        "        sim = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
        "\n",
        "        attn = sim.softmax(dim = -1)\n",
        "        dropped_attn = self.dropout(attn)\n",
        "\n",
        "        out = einsum('b h i j, b h j d -> b h i d', dropped_attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)', h = h)\n",
        "        return self.to_out(out), attn\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, num_tokens, dim, depth, heads, dim_head, attn_dropout, ff_dropout):\n",
        "        super().__init__()\n",
        "        self.embeds = nn.Embedding(num_tokens, dim)\n",
        "        self.layers = nn.ModuleList([])\n",
        "\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = attn_dropout)),\n",
        "                PreNorm(dim, FeedForward(dim, dropout = ff_dropout)),\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x, return_attn = False):\n",
        "        x = self.embeds(x)\n",
        "\n",
        "        post_softmax_attns = []\n",
        "\n",
        "        for attn, ff in self.layers:\n",
        "            attn_out, post_softmax_attn = attn(x)\n",
        "            post_softmax_attns.append(post_softmax_attn)\n",
        "\n",
        "            x = x + attn_out\n",
        "            x = ff(x) + x\n",
        "\n",
        "        if not return_attn:\n",
        "            return x\n",
        "\n",
        "        return x, torch.stack(post_softmax_attns)\n",
        "\n",
        "class MLP_TT(nn.Module):\n",
        "    def __init__(self, dims, act = None):\n",
        "        super().__init__()\n",
        "        dims_pairs = list(zip(dims[:-1], dims[1:]))\n",
        "        layers = []\n",
        "        for ind, (dim_in, dim_out) in enumerate(dims_pairs):\n",
        "            is_last = ind >= (len(dims_pairs) - 1)\n",
        "            linear = nn.Linear(dim_in, dim_out)\n",
        "            layers.append(linear)\n",
        "\n",
        "            if is_last:\n",
        "                continue\n",
        "\n",
        "            act = default(act, nn.ReLU())\n",
        "            layers.append(act)\n",
        "\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.mlp(x)\n",
        "\n",
        "\n",
        "class TabTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        categories, \n",
        "        num_continuous,\n",
        "        dim, \n",
        "        depth, \n",
        "        heads, \n",
        "        dim_head = 16,\n",
        "        dim_out = 1,\n",
        "        mlp_hidden_mults = (4, 2),\n",
        "        mlp_act = None,\n",
        "        num_special_tokens = 2,\n",
        "        continuous_mean_std = None,\n",
        "        attn_dropout = 0.,\n",
        "        ff_dropout = 0.\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_categories = len(categories)\n",
        "        self.num_unique_categories = sum(categories)\n",
        "\n",
        "\n",
        "        self.num_special_tokens = num_special_tokens\n",
        "        total_tokens = self.num_unique_categories + num_special_tokens\n",
        "\n",
        "        if self.num_unique_categories > 0:\n",
        "            categories_offset = F.pad(torch.tensor(list(categories)), (1, 0), value = num_special_tokens)\n",
        "            categories_offset = categories_offset.cumsum(dim = -1)[:-1]\n",
        "            self.register_buffer('categories_offset', categories_offset)\n",
        "\n",
        "        self.num_continuous = num_continuous\n",
        "\n",
        "        if self.num_continuous > 0:\n",
        "            if exists(continuous_mean_std):\n",
        "                assert continuous_mean_std.shape == (num_continuous, 2), f'continuous_mean_std must have a shape of ({num_continuous}, 2) where the last dimension contains the mean and variance respectively'\n",
        "            self.register_buffer('continuous_mean_std', continuous_mean_std)\n",
        "\n",
        "            self.norm = nn.LayerNorm(num_continuous)\n",
        "\n",
        "\n",
        "        \n",
        "        self.transformer = Transformer(\n",
        "            num_tokens = total_tokens,\n",
        "            dim = dim,\n",
        "            depth = depth,\n",
        "            heads = heads,\n",
        "            dim_head = dim_head,\n",
        "            attn_dropout = attn_dropout,\n",
        "            ff_dropout = ff_dropout\n",
        "        )\n",
        "\n",
        "\n",
        "        input_size = (dim * self.num_categories) + num_continuous\n",
        "        l = input_size // 8\n",
        "\n",
        "        hidden_dimensions = list(map(lambda t: l * t, mlp_hidden_mults))\n",
        "        all_dimensions = [input_size, *hidden_dimensions, dim_out]\n",
        "        \n",
        "        \n",
        "        self.mlp = MLP_TT(all_dimensions, act = mlp_act)\n",
        "\n",
        "    def forward(self, x_categ, x_cont, return_attn = False):\n",
        "        xs = []\n",
        "\n",
        "        if self.num_unique_categories > 0:\n",
        "            x_categ += self.categories_offset\n",
        "\n",
        "            x, attns = self.transformer(x_categ, return_attn = True)\n",
        "            xs.append(x)\n",
        "\n",
        "        if self.num_continuous > 0:\n",
        "            if exists(self.continuous_mean_std):\n",
        "                mean, std = self.continuous_mean_std.unbind(dim = -1)\n",
        "                x_cont = (x_cont - mean) / std\n",
        "\n",
        "            normed_cont = self.norm(x_cont)\n",
        "            xs.append(normed_cont)\n",
        "\n",
        "        x = torch.cat(xs, dim = -1)\n",
        "        return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:38:41.853670Z",
          "iopub.execute_input": "2023-04-18T20:38:41.854083Z",
          "iopub.status.idle": "2023-04-18T20:38:41.951892Z",
          "shell.execute_reply.started": "2023-04-18T20:38:41.854047Z",
          "shell.execute_reply": "2023-04-18T20:38:41.950512Z"
        },
        "trusted": true,
        "id": "b0RtHRV6tM79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "VIjc34_AtM8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class _TokenInitialization(enum.Enum):\n",
        "    UNIFORM = 'uniform'\n",
        "    NORMAL = 'normal'\n",
        "\n",
        "    @classmethod\n",
        "    def from_str(cls, initialization: str) -> '_TokenInitialization':\n",
        "        try:\n",
        "            return cls(initialization)\n",
        "        except ValueError:\n",
        "            valid_values = [x.value for x in _TokenInitialization]\n",
        "            raise ValueError(f'initialization must be one of {valid_values}')\n",
        "\n",
        "    def apply(self, x: torch.Tensor, d: int) -> None:\n",
        "        d_sqrt_inv = 1 / math.sqrt(d)\n",
        "        if self == _TokenInitialization.UNIFORM:\n",
        "            nn.init.uniform_(x, a=-d_sqrt_inv, b=d_sqrt_inv)\n",
        "        elif self == _TokenInitialization.NORMAL:\n",
        "            nn.init.normal_(x, std=d_sqrt_inv)\n",
        "\n",
        "class CategoricalFeatureTokenizer(nn.Module):\n",
        "    category_offsets: torch.Tensor\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        cardinalities: List[int],\n",
        "        d_token: int,\n",
        "        bias: bool,\n",
        "        initialization: str,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        assert cardinalities, 'cardinalities must be non-empty'\n",
        "        assert d_token > 0, 'd_token must be positive'\n",
        "        initialization_ = _TokenInitialization.from_str(initialization)\n",
        "\n",
        "        category_offsets = torch.tensor([0] + cardinalities[:-1]).cumsum(0)\n",
        "        self.register_buffer('category_offsets', category_offsets, persistent=False)\n",
        "        self.embeddings = nn.Embedding(sum(cardinalities), d_token)\n",
        "        self.bias = nn.Parameter(torch.Tensor(len(cardinalities), d_token)) if bias else None\n",
        "\n",
        "        for parameter in [self.embeddings.weight, self.bias]:\n",
        "            if parameter is not None:\n",
        "                initialization_.apply(parameter, d_token)\n",
        "\n",
        "    @property\n",
        "    def n_tokens(self) -> int:\n",
        "        return len(self.category_offsets)\n",
        "\n",
        "    @property\n",
        "    def d_token(self) -> int:\n",
        "        return self.embeddings.embedding_dim\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.embeddings(x + self.category_offsets[None])\n",
        "        if self.bias is not None:\n",
        "            x = x + self.bias[None]\n",
        "        return x\n",
        "\n",
        "\n",
        "class FeatureTokenizer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_num_features: int,\n",
        "        cat_cardinalities: List[int],\n",
        "        d_token: int,\n",
        "        preproc_type: str,\n",
        "        cat_preproc_type: str,\n",
        "        preproc_args: dict,\n",
        "        positional: bool,\n",
        "        tf: bool\n",
        "    ) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "        assert n_num_features >= 0, 'n_num_features must be non-negative'\n",
        "        assert (\n",
        "            n_num_features or cat_cardinalities\n",
        "        ), 'at least one of n_num_features or cat_cardinalities must be positive/non-empty'\n",
        "        self.initialization = 'uniform'\n",
        "        self.n_num_features = n_num_features\n",
        "        self.d = d_token\n",
        "        self.tf = tf\n",
        "        self.args = preproc_args\n",
        "        self.preproc_type = preproc_type\n",
        "        self.cat_preproc_type = cat_preproc_type\n",
        "        if preproc_type == 'ARM' or preproc_type == 'ARM_Bin':\n",
        "            self.attn_layer = SparseAttLayer(8, n_num_features , d_token, d_token, d_token, 1.7)\n",
        "        if n_num_features:\n",
        "            if preproc_type == 'Periodic':\n",
        "                self.num_tokenizer = Periodic(**preproc_args)\n",
        "                self.d = self.d * 2\n",
        "            elif preproc_type == 'Linear':\n",
        "                self.num_tokenizer = LinearEmbeddings(**preproc_args)\n",
        "            elif preproc_type == 'AutoDis':\n",
        "                self.num_tokenizer = AutoDis(**preproc_args)\n",
        "            elif preproc_type == 'Tokens' or preproc_type == 'ARM':\n",
        "                self.num_tokenizer = FeaturesTokenizer(**preproc_args)\n",
        "            elif preproc_type == 'SoftEmbedding':\n",
        "                self.num_tokenizer = SoftEmbedding(**preproc_args)\n",
        "            elif preproc_type == 'BinEncoding' or preproc_type == 'ARM_Bin':\n",
        "                self.num_tokenizer = BinEncoding(**preproc_args)\n",
        "            elif preproc_type == 'None':\n",
        "                self.num_tokenizer = None\n",
        "        else:\n",
        "            self.num_tokenizer = None\n",
        "        if cat_preproc_type == 'Lookup' or cat_preproc_type == 'ARM':    \n",
        "            self.cat_tokenizer = (\n",
        "                CategoricalFeatureTokenizer(\n",
        "                    cat_cardinalities, self.d, True, self.initialization\n",
        "                )\n",
        "                if cat_cardinalities\n",
        "                else None\n",
        "            )\n",
        "        elif cat_preproc_type == 'TT':\n",
        "            self.cat_tokenizer = (\n",
        "                TabTransformer(\n",
        "                    num_continuous=0,\n",
        "                    categories=cat_cardinalities, \n",
        "                    dim=self.d, \n",
        "                    depth=3,\n",
        "                    heads=8,\n",
        "                )\n",
        "                if cat_cardinalities\n",
        "                else None\n",
        "            )\n",
        "        if cat_preproc_type == 'ARM':\n",
        "            self.cat_attn_layer = SparseAttLayer(8, len(cat_cardinalities), self.d, self.d, 16, 1.7)\n",
        "        if positional:\n",
        "            self.positional = PositionalEncoding(self.d, self.n_num_features, 0.1, True)\n",
        "        else:\n",
        "            self.positional = None\n",
        "\n",
        "    @property\n",
        "    def n_tokens(self) -> int:\n",
        "        return self.n_num_features + self.cat_tokenizer.n_tokens\n",
        "        \n",
        "    @property\n",
        "    def d_token(self) -> int:\n",
        "        return self.d\n",
        "\n",
        "    def forward(self, x_num: Optional[torch.Tensor], x_cat: Optional[torch.Tensor]) -> torch.Tensor:\n",
        "        if self.num_tokenizer is None:\n",
        "            return x_num[..., None]\n",
        "        assert (\n",
        "            x_num is not None or x_cat is not None\n",
        "        ), 'At least one of x_num and x_cat must be presented'\n",
        "        assert _all_or_none(\n",
        "            [self.num_tokenizer, x_num]\n",
        "        ), 'If self.num_tokenizer is (not) None, then x_num must (not) be None'\n",
        "        assert _all_or_none(\n",
        "            [self.cat_tokenizer, x_cat]\n",
        "        ), 'If self.cat_tokenizer is (not) None, then x_cat must (not) be None'\n",
        "        x = []\n",
        "        if self.num_tokenizer is not None:\n",
        "            if self.positional is not None:\n",
        "                x.append(self.positional(self.num_tokenizer(x_num)))\n",
        "            else:\n",
        "                x.append(self.num_tokenizer(x_num))\n",
        "        if self.cat_tokenizer is not None:\n",
        "            if self.cat_preproc_type == 'TT':\n",
        "                x.append(self.cat_tokenizer(x_cat, None))\n",
        "            elif self.cat_preproc_type == 'ARM':\n",
        "                temp = self.cat_tokenizer(x_cat)\n",
        "                w = self.cat_attn_layer(temp)\n",
        "                w = torch.clamp(w, -1e5, 1e5)\n",
        "                x_cat_arm = torch.exp(torch.einsum('bfe,bkof->bkoe', temp, w))          \n",
        "                x_cat_arm = rearrange(x_cat_arm, 'b k o e -> b (k o) e')\n",
        "                x_cat_arm = torch.clamp(x_cat_arm, -1e5, 1e5)\n",
        "                x.append(x_cat_arm)\n",
        "            else:\n",
        "                x.append(self.cat_tokenizer(x_cat))\n",
        "        if self.preproc_type == 'ARM' or self.preproc_type == 'ARM_Bin':\n",
        "            e = x[0]\n",
        "            arm_weight = self.attn_layer(e)                             \n",
        "            arm_weight = torch.clamp(arm_weight, -1e5, 1e5)\n",
        "            x_arm = torch.exp(torch.einsum('bfe,bkof->bkoe', e, arm_weight))          \n",
        "            x_arm = rearrange(x_arm, 'b k o e -> b (k o) e')\n",
        "            x_arm = torch.clamp(x_arm, -1e5, 1e5)\n",
        "            x[0] = x_arm\n",
        "            x = torch.cat(x, dim=1)\n",
        "            if not self.tf:\n",
        "                return x.view(x_arm.shape[0], -1)\n",
        "            else:\n",
        "                return x\n",
        "                \n",
        "        if not self.tf:\n",
        "            return x[0].view(x[0].shape[0], -1) if len(x) == 1 else torch.cat(x, dim=1).view(x[0].shape[0], -1)\n",
        "        else:\n",
        "            return x[0] if len(x) == 1 else torch.cat(x, dim=1)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:38:42.609722Z",
          "iopub.execute_input": "2023-04-18T20:38:42.610624Z",
          "iopub.status.idle": "2023-04-18T20:38:42.643969Z",
          "shell.execute_reply.started": "2023-04-18T20:38:42.610576Z",
          "shell.execute_reply": "2023-04-18T20:38:42.642900Z"
        },
        "trusted": true,
        "id": "dRcWrar4tM8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union, cast\n",
        "\n",
        "def reglu(x: torch.Tensor) -> torch.Tensor:\n",
        "    assert x.shape[-1] % 2 == 0\n",
        "    a, b = x.chunk(2, dim=-1)\n",
        "    return a * F.relu(b)\n",
        "\n",
        "\n",
        "def geglu(x: torch.Tensor) -> torch.Tensor:\n",
        "    assert x.shape[-1] % 2 == 0\n",
        "    a, b = x.chunk(2, dim=-1)\n",
        "    return a * F.gelu(b)\n",
        "\n",
        "\n",
        "\n",
        "ModuleType = Union[str, Callable[..., nn.Module]]\n",
        "_INTERNAL_ERROR_MESSAGE = 'Internal error. Please, open an issue.'\n",
        "\n",
        "\n",
        "def _is_glu_activation(activation: ModuleType):\n",
        "    return (\n",
        "        isinstance(activation, str)\n",
        "        and activation.endswith('GLU')\n",
        "        or activation in [ReGLU, GEGLU]\n",
        "    )\n",
        "\n",
        "\n",
        "def _all_or_none(values):\n",
        "    return all(x is None for x in values) or all(x is not None for x in values)\n",
        "\n",
        "\n",
        "class ReGLU(nn.Module):\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return reglu(x)\n",
        "\n",
        "\n",
        "class GEGLU(nn.Module):\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return geglu(x)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:38:43.182592Z",
          "iopub.execute_input": "2023-04-18T20:38:43.183486Z",
          "iopub.status.idle": "2023-04-18T20:38:43.193495Z",
          "shell.execute_reply.started": "2023-04-18T20:38:43.183448Z",
          "shell.execute_reply": "2023-04-18T20:38:43.192091Z"
        },
        "trusted": true,
        "id": "wWNm7Fd2tM8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_baseline_transformer_subconfig() -> Dict[str, Any]:\n",
        "    return {\n",
        "        'attention_n_heads': 8,\n",
        "        'attention_initialization': 'kaiming',\n",
        "        'ffn_activation': 'ReGLU',\n",
        "        'attention_normalization': 'LayerNorm',\n",
        "        'ffn_normalization': 'LayerNorm',\n",
        "        'prenormalization': True,\n",
        "        'first_prenormalization': False,\n",
        "        'last_layer_query_idx': None,\n",
        "        'n_tokens': None,\n",
        "        'kv_compression_ratio': None,\n",
        "        'kv_compression_sharing': None,\n",
        "        'head_activation': 'ReLU',\n",
        "        'head_normalization': 'LayerNorm',\n",
        "    }\n",
        "\n",
        "\n",
        "def get_default_transformer_config(n_blocks: int = 3) -> Dict[str, Any]:\n",
        "    assert 1 <= n_blocks <= 6\n",
        "    grid = {\n",
        "        'd_token': [96, 128, 192, 256, 320, 384],\n",
        "        'attention_dropout': [0.1, 0.15, 0.2, 0.25, 0.3, 0.35],\n",
        "        'ffn_dropout': [0.0, 0.05, 0.1, 0.15, 0.2, 0.25],\n",
        "    }\n",
        "    arch_subconfig = {k: v[n_blocks - 1] for k, v in grid.items()}  # type: ignore\n",
        "    baseline_subconfig = get_baseline_transformer_subconfig()\n",
        "    ffn_d_hidden_factor = (\n",
        "        (4 / 3) if _is_glu_activation(baseline_subconfig['ffn_activation']) else 2.0\n",
        "    )\n",
        "    return {\n",
        "        'n_blocks': n_blocks,\n",
        "        'residual_dropout': 0.0,\n",
        "        'ffn_d_hidden': int(arch_subconfig['d_token'] * ffn_d_hidden_factor),\n",
        "        **arch_subconfig,\n",
        "        **baseline_subconfig,\n",
        "    }"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:38:43.518382Z",
          "iopub.execute_input": "2023-04-18T20:38:43.518783Z",
          "iopub.status.idle": "2023-04-18T20:38:43.529027Z",
          "shell.execute_reply.started": "2023-04-18T20:38:43.518737Z",
          "shell.execute_reply": "2023-04-18T20:38:43.527918Z"
        },
        "trusted": true,
        "id": "HiAM9ePJtM8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics"
      ],
      "metadata": {
        "id": "zT73dbBKtM8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Metric():\n",
        "    def __init__(self, metric, higher_is_better=True, name='name', optimize=False, discrete=False, **kwargs):\n",
        "        self.name = name\n",
        "        self.higher_is_better = higher_is_better\n",
        "        self.optimize = optimize\n",
        "        self.discrete = discrete\n",
        "        self.metric = metric\n",
        "        self.best_thr = 0.5\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.name)\n",
        "\n",
        "    def __call__(self, y_true, y_pred, thr=0.5, use_best=False):\n",
        "        if self.discrete:\n",
        "            return self.metric(y_true, y_pred, thr=thr if not use_best else self.best_thr)\n",
        "        else:\n",
        "            return self.metric(y_true, y_pred)\n",
        "\n",
        "    def find_threshold(self, y_true, y_pred):\n",
        "        if self.optimize:\n",
        "            w0 = [0.5]\n",
        "            res = fmin(self.opt, w0, args=(y_true, y_pred), disp=0)[0]\n",
        "            self.best_thr = res\n",
        "            return res\n",
        "        else:\n",
        "            return 0.5\n",
        "\n",
        "    def opt(self, w, y_true, y_pred):\n",
        "        return (-1) ** (self.higher_is_better) * self(y_true, y_pred, w[0])\n",
        "\n",
        "\n",
        "def f1_custom(y_true, y_pred, thr=0.5):\n",
        "    return f1_score(y_true, y_pred > thr, average='micro')\n",
        "\n",
        "\n",
        "def f1_macro(y_true, y_pred, thr=0.5):\n",
        "    return f1_score(y_true, y_pred > thr, average='macro')\n",
        "\n",
        "\n",
        "def acc_score(y_true, y_pred, thr=0.5):\n",
        "    return accuracy_score(y_true, y_pred > thr)\n",
        "\n",
        "\n",
        "def bacc_score(y_true, y_pred, thr=0.5):\n",
        "    return balanced_accuracy_score(y_true, y_pred > thr)\n",
        "\n",
        "\n",
        "class MetricFactory:\n",
        "    def __init__(self, ):\n",
        "        self.metrics = {\n",
        "            'auc': Metric(metric=roc_auc_score, higher_is_better=True, name='auc', optimize=False, discrete=False),\n",
        "            'log-loss': Metric(metric=log_loss, higher_is_better=False, name='log-loss', optimize=False,\n",
        "                              discrete=False),\n",
        "            'f1': Metric(metric=f1_custom, higher_is_better=True, name='f1', optimize=True, discrete=True),\n",
        "            'f1-macro': Metric(metric=f1_macro, higher_is_better=True, name='f1_macro', optimize=True, discrete=True),\n",
        "            'balanced-acc': Metric(metric=bacc_score, higher_is_better=True, name='balanced-acc', optimize=True,\n",
        "                                   discrete=True),\n",
        "            'acc': Metric(metric=acc_score, higher_is_better=True, name='acc', optimize=True, discrete=True),\n",
        "            'mse': Metric(metric=mean_squared_error, higher_is_better=False, name='mse', optimize=False, discrete=False),\n",
        "            'r2': Metric(metric=r2_score, higher_is_better=True, name='r2', optimize=False, discrete=False),\n",
        "            'mae': Metric(metric=mean_absolute_error, higher_is_better=False, name='mae', optimize=False, discrete=False)\n",
        "        }\n",
        "\n",
        "    def get_allowed(self):\n",
        "        return sorted(list(self.metrics.keys()))\n",
        "\n",
        "    def add(self, metric_name, metric_class):\n",
        "        self.metrics[metric_name] = metric_class\n",
        "        return self\n",
        "\n",
        "    def remove(self, metric_name):\n",
        "        del self.models[metric_name]\n",
        "        return self\n",
        "\n",
        "    def __getitem__(self, metric_name):\n",
        "        return deepcopy(self.metrics[metric_name])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:38:44.228188Z",
          "iopub.execute_input": "2023-04-18T20:38:44.228570Z",
          "iopub.status.idle": "2023-04-18T20:38:44.247331Z",
          "shell.execute_reply.started": "2023-04-18T20:38:44.228535Z",
          "shell.execute_reply": "2023-04-18T20:38:44.246036Z"
        },
        "trusted": true,
        "id": "B8gweSgPtM8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and evaluation"
      ],
      "metadata": {
        "id": "5UyQ2ZMDtM8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(\n",
        "    outputs,\n",
        "    targets,\n",
        ") -> Dict[str, float]:\n",
        "    metrics = {}\n",
        "    \n",
        "    y_true = np.array(targets.cpu())\n",
        "    y_pred = (np.array(outputs.detach().cpu()))\n",
        "    \n",
        "    mse = metric_factory['mse']\n",
        "    mse_score = mse(y_true, y_pred)\n",
        "    \n",
        "    mae = metric_factory['mae']\n",
        "    mae_score = mae(y_true, y_pred)\n",
        "    \n",
        "    r2 = metric_factory['r2']\n",
        "    r2_score = r2(y_true, y_pred)\n",
        "    \n",
        "    metrics['rmse'] = np.sqrt(mse_score)\n",
        "    metrics['mae'] = mae_score\n",
        "    metrics['r2'] = r2_score\n",
        "    \n",
        "    return metrics"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:38:45.195496Z",
          "iopub.execute_input": "2023-04-18T20:38:45.196190Z",
          "iopub.status.idle": "2023-04-18T20:38:45.203339Z",
          "shell.execute_reply.started": "2023-04-18T20:38:45.196151Z",
          "shell.execute_reply": "2023-04-18T20:38:45.202040Z"
        },
        "trusted": true,
        "id": "22ItyUDNtM8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch_ftt(\n",
        "    model: nn.Module,\n",
        "    dataloader: torch.utils.data.DataLoader,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    criterion: torch.nn.Module,\n",
        "    device: torch.device,\n",
        "    epoch: int,\n",
        "    silent: bool\n",
        ") -> None:\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = []\n",
        "    batch_metrics_list = defaultdict(list)\n",
        "    if not silent:\n",
        "        for i, (data, targets) in tqdm(\n",
        "            enumerate(dataloader),\n",
        "            total=len(dataloader),\n",
        "        ):\n",
        "\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "            data_num = data[:, :-cat_len]\n",
        "            data_cat = data[:, -cat_len:].long()\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(data_num, data_cat)\n",
        "            loss = criterion(pred, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    else:\n",
        "        for i, (data, targets) in enumerate(dataloader):\n",
        "\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "            data_num = data[:, :-cat_len]\n",
        "            data_cat = data[:, -cat_len:].long()\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(data_num, data_cat)\n",
        "            loss = criterion(pred, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:38:45.831291Z",
          "iopub.execute_input": "2023-04-18T20:38:45.831984Z",
          "iopub.status.idle": "2023-04-18T20:38:45.842256Z",
          "shell.execute_reply.started": "2023-04-18T20:38:45.831945Z",
          "shell.execute_reply": "2023-04-18T20:38:45.841070Z"
        },
        "trusted": true,
        "id": "roF37W-EtM8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_epoch_ftt(\n",
        "    model: torch.nn.Module,\n",
        "    dataloader: torch.utils.data.DataLoader,\n",
        "    criterion: torch.nn.Module,\n",
        "    scheduler: torch.optim.lr_scheduler,\n",
        "    writer: list,\n",
        "    device: torch.device,\n",
        "    epoch: int,\n",
        "    dataset: str,\n",
        "    glob_silent: bool,\n",
        "    silent: bool\n",
        ") -> None:\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = []\n",
        "    batch_metrics_list = defaultdict(list)\n",
        "    \n",
        "    true_val = None\n",
        "    pred_val = None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if dataset == 'train':\n",
        "            desc = 'loop over train batches'\n",
        "        else:\n",
        "            desc = 'loop over test batches'\n",
        "\n",
        "        if not glob_silent:\n",
        "            for i, (data, targets) in tqdm(\n",
        "                enumerate(dataloader),\n",
        "                total=len(dataloader),\n",
        "                desc=desc,\n",
        "            ):\n",
        "\n",
        "                data, targets = data.to(device), targets.to(device)\n",
        "                data_num = data[:, :-cat_len]\n",
        "                data_cat = data[:, -cat_len:].long()\n",
        "                outputs = model(data_num, data_cat)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "                epoch_loss.append(loss.item())\n",
        "\n",
        "                if true_val is None:\n",
        "                    true_val = targets\n",
        "                else:\n",
        "                    true_val = torch.cat((true_val, targets), 0)\n",
        "                \n",
        "                if pred_val is None:\n",
        "                    pred_val = outputs\n",
        "                else:\n",
        "                    pred_val = torch.cat((pred_val, outputs), 0)\n",
        "        else: \n",
        "            for i, (data, targets) in enumerate(dataloader):\n",
        "\n",
        "                data, targets = data.to(device), targets.to(device)\n",
        "                data_num = data[:, :-cat_len]\n",
        "                data_cat = data[:, -cat_len:].long()\n",
        "                outputs = model(data_num, data_cat)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "                epoch_loss.append(loss.item())\n",
        "\n",
        "                if true_val is None:\n",
        "                    true_val = targets\n",
        "                else:\n",
        "                    true_val = torch.cat((true_val, targets), 0)\n",
        "                \n",
        "                if pred_val is None:\n",
        "                    pred_val = outputs\n",
        "                else:\n",
        "                    pred_val = torch.cat((pred_val, outputs), 0)\n",
        "                    \n",
        "        batch_metrics = compute_metrics(\n",
        "            outputs = pred_val,\n",
        "            targets = true_val\n",
        "        )\n",
        "        \n",
        "        for metric_name, metric_value in batch_metrics.items():\n",
        "            batch_metrics_list[metric_name].append(metric_value)\n",
        "\n",
        "\n",
        "        loss = criterion(pred_val, true_val)\n",
        "        if dataset == 'test' and scheduler is not None:\n",
        "            scheduler.step(loss)\n",
        "        val_loss = loss.item()\n",
        "        \n",
        "        if not silent:\n",
        "            if dataset == 'train':\n",
        "                print(f'Train loss: {val_loss}\\n')\n",
        "            else:\n",
        "                print(f'Test loss: {val_loss}\\n')\n",
        "\n",
        "        writer.append((batch_metrics_list, val_loss))\n",
        "        \n",
        "        for metric_name, metric_value_list in batch_metrics_list.items():\n",
        "            metric_value = metric_value_list[0]\n",
        "            if not silent:\n",
        "                if dataset == 'train':\n",
        "                    print(f'Train {metric_name}: {metric_value}\\n')\n",
        "                else:\n",
        "                    print(f'Test {metric_name}: {metric_value}\\n')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:38:46.237145Z",
          "iopub.execute_input": "2023-04-18T20:38:46.237571Z",
          "iopub.status.idle": "2023-04-18T20:38:46.259433Z",
          "shell.execute_reply.started": "2023-04-18T20:38:46.237530Z",
          "shell.execute_reply": "2023-04-18T20:38:46.257199Z"
        },
        "trusted": true,
        "id": "nLqSasaktM8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_ftt(\n",
        "    n_epochs: int,\n",
        "    model: torch.nn.Module,\n",
        "    train_dataloader: torch.utils.data.DataLoader,\n",
        "    val_dataloader: torch.utils.data.DataLoader,\n",
        "    test_dataloader: torch.utils.data.DataLoader,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    scheduler: torch.optim.lr_scheduler,\n",
        "    criterion: torch.nn.Module,\n",
        "    writer_train: list,\n",
        "    writer_val: list,\n",
        "    writer_test: list,\n",
        "    device: torch.device,\n",
        "    patience=10,\n",
        "    silent=False,\n",
        "    glob_silent=False\n",
        ") -> None:\n",
        "    best_epoch = -1\n",
        "    best_metric = np.inf\n",
        "    best_r2 = np.inf\n",
        "    best_mae = np.inf\n",
        "    \n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        if not silent:\n",
        "            print(f\"Epoch [{epoch+1} / {n_epochs}]\\n\")\n",
        "\n",
        "        train_epoch_ftt(\n",
        "            model=model,\n",
        "            dataloader=train_dataloader,\n",
        "            optimizer=optimizer,\n",
        "            criterion=criterion,\n",
        "            device=device,\n",
        "            epoch=epoch,\n",
        "            silent=silent\n",
        "        )\n",
        "        evaluate_epoch_ftt(\n",
        "            model=model,\n",
        "            dataloader=train_dataloader,\n",
        "            criterion=criterion,\n",
        "            scheduler=scheduler,\n",
        "            writer=writer_train,\n",
        "            device=device,\n",
        "            epoch=epoch,\n",
        "            dataset='train',\n",
        "            glob_silent=glob_silent,\n",
        "            silent=silent\n",
        "        )\n",
        "        evaluate_epoch_ftt(\n",
        "            model=model,\n",
        "            dataloader=val_dataloader,\n",
        "            criterion=criterion,\n",
        "            scheduler=scheduler,\n",
        "            writer=writer_val,\n",
        "            device=device,\n",
        "            epoch=epoch,\n",
        "            dataset='test',\n",
        "            glob_silent=glob_silent,\n",
        "            silent=silent\n",
        "        )\n",
        "        temp_metric = writer_val[-1][0]['rmse'][0]\n",
        "        if temp_metric < best_metric:\n",
        "            best_epoch = epoch\n",
        "            best_metric = temp_metric\n",
        "            best_r2 = writer_val[-1][0]['r2'][0]\n",
        "            best_mae = writer_val[-1][0]['mae'][0]\n",
        "        elif epoch - best_epoch > patience:\n",
        "            break\n",
        "    evaluate_epoch_ftt(\n",
        "            model=model,\n",
        "            dataloader=test_dataloader,\n",
        "            criterion=criterion,\n",
        "            scheduler=scheduler,\n",
        "            writer=writer_test,\n",
        "            device=device,\n",
        "            epoch=None,\n",
        "            dataset='test',\n",
        "            glob_silent=glob_silent,\n",
        "            silent=silent\n",
        "    )\n",
        "    rmse = writer_test[-1][0]['rmse'][0]\n",
        "    r2 = writer_test[-1][0]['r2'][0]\n",
        "    mae = writer_test[-1][0]['mae'][0]\n",
        "    return best_metric, best_r2, best_mae\n",
        "    "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:38:46.564742Z",
          "iopub.execute_input": "2023-04-18T20:38:46.572205Z",
          "iopub.status.idle": "2023-04-18T20:38:46.591737Z",
          "shell.execute_reply.started": "2023-04-18T20:38:46.572150Z",
          "shell.execute_reply": "2023-04-18T20:38:46.590584Z"
        },
        "trusted": true,
        "id": "VcBPWFwPtM8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "O4Wl5dOktM8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NYC Taxi"
      ],
      "metadata": {
        "id": "jDtvRYlPtM8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "df_nt = fetch_openml(data_id=42729, as_frame=True).frame\n",
        "df_nt = df_nt[df_nt['tip_amount'] <= 20]\n",
        "nf_nt = ['PULocationID', 'DOLocationID', 'passenger_count', 'tolls_amount', 'total_amount',\n",
        "         'lpep_pickup_datetime_day', 'lpep_pickup_datetime_hour', 'lpep_pickup_datetime_minute',\n",
        "        'lpep_dropoff_datetime_day', 'lpep_dropoff_datetime_hour', 'lpep_dropoff_datetime_minute']\n",
        "cf_nt = ['VendorID', 'store_and_fwd_flag', 'RatecodeID', 'extra', 'mta_tax', \n",
        "        'improvement_surcharge', 'trip_type']\n",
        "scaler = StandardScaler()\n",
        "df_nt[nf_nt] = scaler.fit_transform(df_nt[nf_nt])\n",
        "\n",
        "le = LabelEncoder()\n",
        "cc_nt = []\n",
        "for cf_name in cf_nt:\n",
        "    df_nt[cf_name] = le.fit_transform(df_nt[cf_name])\n",
        "    cc_nt.append(len(np.unique(df_nt[cf_name])))\n",
        "tdf = df_nt[cf_nt]\n",
        "df_gsc = df_nt.drop(cf_nt, axis=1)\n",
        "df_nt = df_nt.drop(cf_nt, axis=1)\n",
        "\n",
        "df_nt = pd.concat([df_nt, tdf], axis=1)\n",
        "df_nt_target_name = 'tip_amount'\n",
        "df_nt.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:39:39.531387Z",
          "iopub.execute_input": "2023-04-18T20:39:39.532390Z",
          "iopub.status.idle": "2023-04-18T20:40:02.018501Z",
          "shell.execute_reply.started": "2023-04-18T20:39:39.532353Z",
          "shell.execute_reply": "2023-04-18T20:40:02.017253Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6gCiY20tM8O",
        "outputId": "98f9a14f-e5f6-4df1-c723-4908cae0d305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(581006, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Colleges"
      ],
      "metadata": {
        "id": "jZH6ir19tM8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cl = fetch_openml(data_id=42727, as_frame=True).frame\n",
        "df_cl.fillna(df_cl.median(), inplace=True)\n",
        "nf_cl = ['city', 'state', 'zip', 'latitude', 'longitude', 'admission_rate',\n",
        "        'sat_verbal_midrange', 'sat_math_midrange', 'sat_writing_midrange', 'act_combined_midrange', \n",
        "        'act_english_midrange', 'act_math_midrange', 'act_writing_midrange', 'sat_total_average', 'undergrad_size',\n",
        "        'percent_white', 'percent_black', 'percent_hispanic', 'percent_asian', 'percent_part_time', \n",
        "        'average_cost_academic_year', 'average_cost_program_year', 'tuition_(instate)', 'tuition_(out_of_state)',\n",
        "        'spend_per_student', 'faculty_salary', 'percent_part_time_faculty', 'completion_rate', 'percent_female',\n",
        "        'agege24', 'faminc', 'mean_earnings_6_years', 'median_earnings_6_years', 'mean_earnings_10_years',\n",
        "        'median_earnings_10_years', 'carnegie_basic_classification', 'carnegie_undergraduate', 'carnegie_size',\n",
        "        'religious_affiliation', ]\n",
        "cf_cl = ['predominant_degree', 'highest_degree', 'ownership', 'region', 'gender']\n",
        "le = LabelEncoder()\n",
        "df_cl['city'] = le.fit_transform(df_cl['city'])\n",
        "df_cl['state'] = le.fit_transform(df_cl['state'])\n",
        "df_cl['zip'] = le.fit_transform(df_cl['zip'])\n",
        "df_cl['carnegie_basic_classification'] = le.fit_transform(df_cl['carnegie_basic_classification'])\n",
        "df_cl['carnegie_undergraduate'] = le.fit_transform(df_cl['carnegie_undergraduate'])\n",
        "df_cl['carnegie_size'] = le.fit_transform(df_cl['carnegie_size'])\n",
        "df_cl['religious_affiliation'] = le.fit_transform(df_cl['religious_affiliation'])\n",
        "scaler = StandardScaler()\n",
        "df_cl[nf_cl] = scaler.fit_transform(df_cl[nf_cl])\n",
        "\n",
        "le = LabelEncoder()\n",
        "cc_cl = []\n",
        "for cf_name in cf_cl:\n",
        "    df_cl[cf_name] = le.fit_transform(df_cl[cf_name])\n",
        "    cc_cl.append(len(np.unique(df_cl[cf_name])))\n",
        "tdf = df_cl[cf_cl]\n",
        "df_cl = df_cl.drop(cf_cl, axis=1)\n",
        "\n",
        "df_cl = pd.concat([df_cl, tdf], axis=1)\n",
        "df_cl_target_name = 'percent_pell_grant'\n",
        "df_cl.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:40:06.395696Z",
          "iopub.execute_input": "2023-04-18T20:40:06.396092Z",
          "iopub.status.idle": "2023-04-18T20:40:16.078338Z",
          "shell.execute_reply.started": "2023-04-18T20:40:06.396059Z",
          "shell.execute_reply": "2023-04-18T20:40:16.077194Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHm250QTtM8P",
        "outputId": "f00eb69a-255a-48bf-9c89-02980fa14a95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n",
            "<ipython-input-15-9cb3099fe5ff>:2: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  df_cl.fillna(df_cl.median(), inplace=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7063, 45)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### House sales"
      ],
      "metadata": {
        "id": "P-egzxRDtM8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_hs = fetch_openml(data_id=42731, as_frame=True).frame\n",
        "df_hs.fillna(df_hs.median(), inplace=True)\n",
        "nf_hs = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'yr_built', \n",
        "    'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15', 'date_year', 'date_month', 'date_day']\n",
        "cf_hs = ['floors', 'waterfront', 'view', 'condition', 'grade']\n",
        "le = LabelEncoder()\n",
        "df_hs['zipcode'] = le.fit_transform(df_hs['zipcode'])\n",
        "scaler = StandardScaler()\n",
        "df_hs[nf_hs] = scaler.fit_transform(df_hs[nf_hs])\n",
        "\n",
        "le = LabelEncoder()\n",
        "cc_hs = []\n",
        "for cf_name in cf_hs:\n",
        "    df_hs[cf_name] = le.fit_transform(df_hs[cf_name])\n",
        "    cc_hs.append(len(np.unique(df_hs[cf_name])))\n",
        "tdf = df_hs[cf_hs]\n",
        "df_hs = df_hs.drop(cf_hs, axis=1)\n",
        "\n",
        "\n",
        "df_hs = pd.concat([df_hs, tdf], axis=1)\n",
        "df_hs_target_name = 'price'\n",
        "df_hs.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:40:16.080417Z",
          "iopub.execute_input": "2023-04-18T20:40:16.081313Z",
          "iopub.status.idle": "2023-04-18T20:40:21.485159Z",
          "shell.execute_reply.started": "2023-04-18T20:40:16.081271Z",
          "shell.execute_reply": "2023-04-18T20:40:21.483800Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBpxzDDttM8R",
        "outputId": "bedcc80d-138a-463e-bcc3-469fc7b375c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n",
            "<ipython-input-16-57336a1b0dc4>:2: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  df_hs.fillna(df_hs.median(), inplace=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21613, 22)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Black friday"
      ],
      "metadata": {
        "id": "9mh4k6DDtM8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_bf = fetch_openml(data_id=41540, as_frame=True).frame\n",
        "df_bf.fillna(df_bf.median(), inplace=True)\n",
        "nf_bf = ['Occupation', 'Product_Category_1', 'Product_Category_2', 'Product_Category_3']\n",
        "cf_bf = ['Gender', 'Age', 'City_Category', 'Stay_In_Current_City_Years', 'Marital_Status']\n",
        "le = LabelEncoder()\n",
        "scaler = StandardScaler()\n",
        "df_bf[nf_bf] = scaler.fit_transform(df_bf[nf_bf])\n",
        "\n",
        "le = LabelEncoder()\n",
        "cc_bf = []\n",
        "for cf_name in cf_bf:\n",
        "    df_bf[cf_name] = le.fit_transform(df_bf[cf_name])\n",
        "    cc_bf.append(len(np.unique(df_bf[cf_name])))\n",
        "tdf = df_bf[cf_bf]\n",
        "df_bf = df_bf.drop(cf_bf, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "df_bf = pd.concat([df_bf, tdf], axis=1)\n",
        "df_bf_target_name = 'Purchase'\n",
        "df_bf.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:40:21.486910Z",
          "iopub.execute_input": "2023-04-18T20:40:21.488111Z",
          "iopub.status.idle": "2023-04-18T20:40:30.187603Z",
          "shell.execute_reply.started": "2023-04-18T20:40:21.488061Z",
          "shell.execute_reply": "2023-04-18T20:40:30.186450Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBCg3T2XtM8R",
        "outputId": "dee7a1a1-174a-4d98-82dc-91c278fa1984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n",
            "<ipython-input-17-b48481782e81>:2: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  df_bf.fillna(df_bf.median(), inplace=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(166821, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beijing PM2.5"
      ],
      "metadata": {
        "id": "CW6N3Yy6tM8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_bp = pd.read_csv('./PRSA_data_2010.1.1-2014.12.31.csv')\n",
        "df_bp.drop(['No'], axis=1, inplace=True)\n",
        "df_bp.fillna(df_bp.median(), inplace=True)\n",
        "df_bp = df_bp[df_bp['pm2.5'] <= 600]\n",
        "nf_bp = ['month', 'day', 'hour', 'DEWP', 'TEMP', 'PRES', 'Iws', 'Is', 'Ir']\n",
        "cf_bp = ['year', 'cbwd']\n",
        "le = LabelEncoder()\n",
        "df_bp['year'] = le.fit_transform(df_bp['year'])\n",
        "df_bp['cbwd'] = le.fit_transform(df_bp['cbwd'])\n",
        "scaler = StandardScaler()\n",
        "df_bp[nf_bp] = scaler.fit_transform(df_bp[nf_bp])\n",
        "\n",
        "le = LabelEncoder()\n",
        "cc_bp = []\n",
        "for cf_name in cf_bp:\n",
        "    df_bp[cf_name] = le.fit_transform(df_bp[cf_name])\n",
        "    cc_bp.append(len(np.unique(df_bp[cf_name])))\n",
        "tdf = df_bp[cf_bp]\n",
        "df_bp = df_bp.drop(cf_bp, axis=1)\n",
        "\n",
        "\n",
        "df_bp = pd.concat([df_bp, tdf], axis=1)\n",
        "df_bp_target_name = 'pm2.5'\n",
        "df_bp.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:40:30.190258Z",
          "iopub.execute_input": "2023-04-18T20:40:30.190995Z",
          "iopub.status.idle": "2023-04-18T20:40:30.301275Z",
          "shell.execute_reply.started": "2023-04-18T20:40:30.190951Z",
          "shell.execute_reply": "2023-04-18T20:40:30.300197Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjAdhfaktM8T",
        "outputId": "79108748-2ab3-48e6-b21b-f10bc4e97556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-de4f1e3ddb55>:3: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  df_bp.fillna(df_bp.median(), inplace=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43792, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Brazilian houses"
      ],
      "metadata": {
        "id": "BcQgLKGqtM8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_bh = fetch_openml(data_id=42688, as_frame=True).frame\n",
        "df_bh.fillna(df_bh.median(), inplace=True)\n",
        "df_bh = df_bh[df_bh['total_(BRL)'] <= 40000]\n",
        "nf_bh = ['area', 'rooms', 'bathroom', 'parking_spaces', 'floor', 'hoa_(BRL)', 'rent_amount_(BRL)',\n",
        "        'property_tax_(BRL)', 'fire_insurance_(BRL)']\n",
        "cf_bh = ['city', 'animal', 'furniture']\n",
        "le = LabelEncoder()\n",
        "scaler = StandardScaler()\n",
        "df_bh['city'] = le.fit_transform(df_bh['city'])\n",
        "df_bh['animal'] = le.fit_transform(df_bh['animal'])\n",
        "df_bh['furniture'] = le.fit_transform(df_bh['furniture'])\n",
        "df_bh[nf_bh] = scaler.fit_transform(df_bh[nf_bh])\n",
        "\n",
        "le = LabelEncoder()\n",
        "cc_bh = []\n",
        "for cf_name in cf_bh:\n",
        "    df_bh[cf_name] = le.fit_transform(df_bh[cf_name])\n",
        "    cc_bh.append(len(np.unique(df_bh[cf_name])))\n",
        "tdf = df_bh[cf_bh]\n",
        "df_bh = df_bh.drop(cf_bh, axis=1)\n",
        "\n",
        "\n",
        "df_bh = pd.concat([df_bh, tdf], axis=1)\n",
        "df_bh_target_name = 'total_(BRL)'\n",
        "df_bh.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:40:30.302691Z",
          "iopub.execute_input": "2023-04-18T20:40:30.303382Z",
          "iopub.status.idle": "2023-04-18T20:40:30.688105Z",
          "shell.execute_reply.started": "2023-04-18T20:40:30.303341Z",
          "shell.execute_reply": "2023-04-18T20:40:30.686808Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26_mnWuBtM8U",
        "outputId": "b5b8cbc9-f53d-4f02-d39a-adf7ba36dbb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n",
            "<ipython-input-20-41f5b04907d3>:2: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  df_bh.fillna(df_bh.median(), inplace=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10685, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Runs"
      ],
      "metadata": {
        "id": "omWD_kSetM8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = {'nt': df_nt, 'cl': df_cl, 'hs': df_hs, 'bf': df_bf, 'bp': df_bp, 'bh': df_bh}\n",
        "dfs_shapes = {'nt': df_nt.shape[1]-1, 'cl': df_cl.shape[1]-1, 'hs': df_hs.shape[1]-1, 'bf': df_bf.shape[1]-1, 'bp': df_bp.shape[1]-1, 'bh': df_bh.shape[1]-1}\n",
        "dfs_targets = {'nt': df_nt_target_name, 'cl': df_cl_target_name, 'hs': df_hs_target_name, 'bf': df_bf_target_name, 'bp': df_bp_target_name, 'bh': df_bh_target_name}\n",
        "dfs_cc = {'nt': cc_nt, 'cl': cc_cl, 'hs': cc_hs, 'bf': cc_bf, 'bp': cc_bp, 'bh': cc_bh}\n",
        "dfs_nf = {'nt': nf_nt, 'cl': nf_cl, 'hs': nf_hs, 'bf': nf_bf, 'bp': nf_bp, 'bh': nf_bh}\n",
        "dfs_names = ['nt', 'cl', 'hs', 'bf', 'bp', 'bh']\n",
        "preproc_types = ['Periodic', 'Fourier', 'Linear', 'AutoDis', 'Tokens', 'SoftEmbedding']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:40:30.689844Z",
          "iopub.execute_input": "2023-04-18T20:40:30.690546Z",
          "iopub.status.idle": "2023-04-18T20:40:30.700326Z",
          "shell.execute_reply.started": "2023-04-18T20:40:30.690503Z",
          "shell.execute_reply": "2023-04-18T20:40:30.698928Z"
        },
        "trusted": true,
        "id": "1YMQBJWYtM8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_nt.shape)\n",
        "print(df_cl.shape)\n",
        "print(df_hs.shape)\n",
        "print(df_bf.shape)\n",
        "print(df_bp.shape)\n",
        "print(df_bh.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:40:37.328246Z",
          "iopub.execute_input": "2023-04-18T20:40:37.329189Z",
          "iopub.status.idle": "2023-04-18T20:40:37.335743Z",
          "shell.execute_reply.started": "2023-04-18T20:40:37.329132Z",
          "shell.execute_reply": "2023-04-18T20:40:37.334692Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5xMystbtM8V",
        "outputId": "4f22e0d0-0955-4373-fc31-b9a35bd1bfb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(581006, 19)\n",
            "(7063, 45)\n",
            "(21613, 22)\n",
            "(166821, 10)\n",
            "(43792, 12)\n",
            "(10685, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_preproc_params(dataset, preproc_type, tf, d_embedding):\n",
        "    preproc_params = {}\n",
        "    if preproc_type == 'Periodic':\n",
        "        preproc_params = {'n_features': len(dfs_nf[dataset]), 'n': d_embedding, 'sigma': 0.1, 'trainable': True,\n",
        "                         'initialization': 'normal', 'tf': tf}\n",
        "        preproc_name = 'Periodic'\n",
        "    elif preproc_type == 'Fourier':\n",
        "        preproc_params = {'n_features': len(dfs_nf[dataset]), 'n': d_embedding, 'sigma': 0.1, 'trainable': False,\n",
        "                         'initialization': 'normal', 'tf': tf}\n",
        "        preproc_name = 'Periodic'\n",
        "    elif preproc_type == 'Linear':\n",
        "        preproc_params = {'n_layers': 2, 'n_features': len(dfs_nf[dataset]), \n",
        "                          'd_embeddings': [d_embedding, d_embedding], 'tf': tf}\n",
        "        preproc_name = 'Linear'\n",
        "    elif preproc_type == 'AutoDis':\n",
        "        preproc_params = {'n_features': len(dfs_nf[dataset]), 'd_embedding': d_embedding, 'n_meta_embeddings': 20,\n",
        "                         'temperature': 0.5, 'tf': tf}\n",
        "        preproc_name = 'AutoDis'\n",
        "    elif preproc_type == 'Tokens' or preproc_type == 'ARM':\n",
        "        preproc_params = {'n_features': len(dfs_nf[dataset]), 'd_embedding': d_embedding, 'tf': tf}\n",
        "        preproc_name = preproc_type\n",
        "    elif preproc_type == 'SoftEmbedding':\n",
        "        preproc_params = {'num_embeddings': len(dfs_nf[dataset]), 'embeddings_dim': d_embedding, \n",
        "                          'emb_initializer': None, 'tf': tf}\n",
        "        preproc_name = 'SoftEmbedding'\n",
        "    elif preproc_type == 'BinEncoding' or preproc_type == 'ARM_Bin':\n",
        "        preproc_params = {'bin_edges': bin_edges, 'bins': bins, 'bin_values': bin_values, 'nbins': nbins,\n",
        "                         'tf': tf, 'd_token': d_embedding, 'bias': True, 'initialization': 'normal', \n",
        "                          'device': device}\n",
        "        preproc_name = 'BinEncoding'\n",
        "    return preproc_params, preproc_name"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:40:40.871974Z",
          "iopub.execute_input": "2023-04-18T20:40:40.873225Z",
          "iopub.status.idle": "2023-04-18T20:40:40.885086Z",
          "shell.execute_reply.started": "2023-04-18T20:40:40.873172Z",
          "shell.execute_reply": "2023-04-18T20:40:40.883808Z"
        },
        "trusted": true,
        "id": "JBPbdL9ctM8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = './output/reg/transformer_sepcat/'\n",
        "positional = False\n",
        "tf = True\n",
        "d_embedding = 16"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:40:43.651782Z",
          "iopub.execute_input": "2023-04-18T20:40:43.652513Z",
          "iopub.status.idle": "2023-04-18T20:40:43.658456Z",
          "shell.execute_reply.started": "2023-04-18T20:40:43.652472Z",
          "shell.execute_reply": "2023-04-18T20:40:43.656604Z"
        },
        "trusted": true,
        "id": "dt80Dvy-tM8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:40:43.843689Z",
          "iopub.execute_input": "2023-04-18T20:40:43.844402Z",
          "iopub.status.idle": "2023-04-18T20:40:43.990137Z",
          "shell.execute_reply.started": "2023-04-18T20:40:43.844362Z",
          "shell.execute_reply": "2023-04-18T20:40:43.988729Z"
        },
        "trusted": true,
        "id": "UCwmL2dutM8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for df_name in tqdm(dfs_names):\n",
        "    for preproc_type in tqdm(preproc_types):\n",
        "        temp_path = df_name + '/' + preproc_type + '/'\n",
        "        X = dfs[df_name].drop([dfs_targets[df_name]], axis=1)\n",
        "        y = dfs[df_name][dfs_targets[df_name]]\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
        "        X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(X_train, y_train, test_size=0.2, shuffle=False)\n",
        "        temp = []\n",
        "        final_res = defaultdict(list)\n",
        "        n_runs=15\n",
        "        silent=True,\n",
        "        glob_silent=True\n",
        "        best_metric = np.inf\n",
        "        best_r2 = np.inf\n",
        "        best_mae = np.inf\n",
        "        cat_len = len(dfs_cc[df_name])\n",
        "        seeds = np.random.randint(1, 100500, 15)\n",
        "        for i in range(n_runs):\n",
        "            if not silent:\n",
        "                print(f'Run {i+1}:')\n",
        "                print()\n",
        "            set_global_seed(seeds[i])\n",
        "            res_metrics = defaultdict(list)\n",
        "            X_train_t = torch.from_numpy(X_train_t.values).float()\n",
        "            y_train_t = torch.from_numpy(y_train_t.values.ravel()).float().unsqueeze(1)\n",
        "            X_test_t = torch.from_numpy(X_test_t.values).float()\n",
        "            y_test_t = torch.from_numpy(y_test_t.values.ravel()).float().unsqueeze(1)\n",
        "            X_test = torch.from_numpy(X_test.values).float()\n",
        "            y_test = torch.from_numpy(y_test.values.ravel()).float().unsqueeze(1)\n",
        "\n",
        "            train_ds = torch.utils.data.TensorDataset(X_train_t, y_train_t)\n",
        "            val_ds = torch.utils.data.TensorDataset(X_test_t, y_test_t)\n",
        "            test_ds = torch.utils.data.TensorDataset(X_test, y_test)\n",
        "            train_dataloader = torch.utils.data.DataLoader(train_ds, batch_size=256, shuffle=True)\n",
        "            val_dataloader = torch.utils.data.DataLoader(val_ds, batch_size=256, shuffle=True)\n",
        "            test_dataloader = torch.utils.data.DataLoader(test_ds, batch_size=256, shuffle=True)\n",
        "\n",
        "            writer_train = []\n",
        "            writer_val = []\n",
        "            writer_test = []\n",
        "  \n",
        "            metric_factory = MetricFactory()\n",
        "            preproc_params, preproc_name = get_preproc_params(df_name, preproc_type, tf, d_embedding)\n",
        "                \n",
        "                \n",
        "            preproc_params['tf'] = True\n",
        "            feature_tokenizer = FeatureTokenizer(len(dfs_nf[df_name]), dfs_cc[df_name], d_embedding, \n",
        "                                                     preproc_name, 'ARM', preproc_params, positional, tf)\n",
        "            transformer_config = get_default_transformer_config(n_blocks=3)\n",
        "            transformer_config['last_layer_query_idx'] = [-1]\n",
        "            transformer_config['kv_compression_ratio'] = None\n",
        "            transformer_config['kv_compression_sharing'] = None\n",
        "            transformer_config['d_out'] = 1\n",
        "            if preproc_name == 'Periodic':\n",
        "                transformer_config['d_token'] = 2 * d_embedding\n",
        "            else:\n",
        "                transformer_config['d_token'] = d_embedding\n",
        "            transformer = rtdl.Transformer(**transformer_config)\n",
        "            model = rtdl.FTTransformer(feature_tokenizer, transformer)\n",
        "            model.to(device)\n",
        "\n",
        "\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=5e-3, weight_decay=0)\n",
        "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=100, eta_min=1e-5)\n",
        "            criterion = torch.nn.MSELoss()\n",
        "            metric_rmse, metric_r2, metric_mae = train_ftt(100, model, train_dataloader, val_dataloader, test_dataloader, optimizer, None, criterion, writer_train,\n",
        "                            writer_val, writer_test, device, 20, silent, glob_silent)\n",
        "                \n",
        "            test_metrics = writer_test[-1][0]\n",
        "            test_loss = writer_test[-1][1]\n",
        "            for key, value in test_metrics.items():\n",
        "                res_metrics[key].append(value[0])\n",
        "            res_metrics['loss'].append(test_loss)\n",
        "            \n",
        "            for key, value in res_metrics.items():\n",
        "                final_res[key].append(np.mean(value))\n",
        "            s = 'run' + str(i + 1) + '.pickle'\n",
        "            with open(path + temp_path + s, 'wb') as f:\n",
        "                pickle.dump(res_metrics, f)\n",
        "    \n",
        "        ans = {}\n",
        "        for key, value in final_res.items():\n",
        "            ans[key] = float(np.mean(value))\n",
        "        \n",
        "        with open(path + temp_path + 'metrics.yml', 'w') as f:\n",
        "            ruamel.yaml.round_trip_dump(ans, f)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T20:42:01.034307Z",
          "iopub.execute_input": "2023-04-18T20:42:01.034740Z",
          "iopub.status.idle": "2023-04-18T21:43:23.863672Z",
          "shell.execute_reply.started": "2023-04-18T20:42:01.034700Z",
          "shell.execute_reply": "2023-04-18T21:43:23.862589Z"
        },
        "trusted": true,
        "id": "31rfCI7NtM8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Binning"
      ],
      "metadata": {
        "id": "YrioHMXZtM8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "\n",
        "\n",
        "\n",
        "def construct_bins(D, nbins):\n",
        "    bin_edges = []\n",
        "    _bins = []\n",
        "    _bin_values = []\n",
        "    rng = np.random.default_rng()\n",
        "    for feature_idx in range(D.shape[1]):\n",
        "        train_column = D.iloc[:, feature_idx].copy()\n",
        "        quantiles = np.linspace(\n",
        "            0.0, 1.0, nbins + 1\n",
        "        ) \n",
        "        bin_edges.append(np.unique(np.quantile(train_column, quantiles)))\n",
        "\n",
        "        _bins.append(np.digitize(\n",
        "                D.iloc[:, feature_idx],\n",
        "                np.r_[-np.inf, bin_edges[feature_idx][1:-1], np.inf],\n",
        "            ).astype(np.int32)\n",
        "            - 1)\n",
        "        _bin_values.append(np.ones_like(D.iloc[:, feature_idx]))\n",
        "    return bin_edges, _bins, _bin_values\n",
        "\n",
        "class BinEncoding(nn.Module):\n",
        "    def __init__(self, bin_edges, bins, bin_values, nbins, tf, d_token, bias, initialization, device):\n",
        "        super().__init__()\n",
        "        self.tf = tf\n",
        "        self.bin_edges = bin_edges\n",
        "        self.bins = bins\n",
        "        self.bin_values = bin_values\n",
        "        self.nbins = nbins\n",
        "        self.d = d_token\n",
        "        self.device = device\n",
        "        \n",
        "        initialization_ = _TokenInitialization.from_str(initialization)\n",
        "        offsets = torch.tensor([0] + ([nbins] * len(bins))[:-1]).cumsum(0)\n",
        "        self.register_buffer('offsets', offsets, persistent=False)\n",
        "        self.embeddings = nn.Embedding(nbins * len(bins), d_token)\n",
        "        self.bias = nn.Parameter(torch.Tensor(len(bins), d_token)) if bias else None\n",
        "        for parameter in [self.embeddings.weight, self.bias]:\n",
        "            if parameter is not None:\n",
        "                initialization_.apply(parameter, d_token)\n",
        "        \n",
        "        \n",
        "    @property\n",
        "    def n_tokens(self) -> int:\n",
        "        \"\"\"The number of tokens.\"\"\"\n",
        "        return len(self.offsets)\n",
        "\n",
        "    @property\n",
        "    def d_token(self) -> int:\n",
        "        \"\"\"The size of one token.\"\"\"\n",
        "        return self.embeddings.embedding_dim\n",
        "        \n",
        "    def forward(self, x):\n",
        "        bins = []\n",
        "        for feature_idx in range(x.shape[1]):\n",
        "            bins.append(np.digitize(x[:, feature_idx].cpu(), np.r_[-np.inf, self.bin_edges[feature_idx][1:-1], np.inf]).astype(np.int32)-1)\n",
        "            \n",
        "        res = torch.tensor(np.stack(bins, axis=1), dtype=torch.long, device=device)\n",
        "        res = self.embeddings(res + self.offsets[None])\n",
        "        if self.bias is not None:\n",
        "            res = res + self.bias[None]\n",
        "        if self.tf:\n",
        "            return res\n",
        "        else:\n",
        "            return res.view(res.shape[0], -1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T21:46:04.865694Z",
          "iopub.execute_input": "2023-04-18T21:46:04.866102Z",
          "iopub.status.idle": "2023-04-18T21:46:05.086330Z",
          "shell.execute_reply.started": "2023-04-18T21:46:04.866061Z",
          "shell.execute_reply": "2023-04-18T21:46:05.085207Z"
        },
        "trusted": true,
        "id": "5MB5lP6EtM8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = './output/reg/transformer_binning/'\n",
        "positional = True\n",
        "tf = True\n",
        "d_embedding = 16\n",
        "nbins = 10"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T23:10:50.258549Z",
          "iopub.execute_input": "2023-04-18T23:10:50.259320Z",
          "iopub.status.idle": "2023-04-18T23:10:50.264850Z",
          "shell.execute_reply.started": "2023-04-18T23:10:50.259277Z",
          "shell.execute_reply": "2023-04-18T23:10:50.263705Z"
        },
        "trusted": true,
        "id": "dlCnnxT2tM8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T23:10:50.465505Z",
          "iopub.execute_input": "2023-04-18T23:10:50.465899Z",
          "iopub.status.idle": "2023-04-18T23:10:50.619693Z",
          "shell.execute_reply.started": "2023-04-18T23:10:50.465862Z",
          "shell.execute_reply": "2023-04-18T23:10:50.618092Z"
        },
        "trusted": true,
        "id": "05KET1cPtM8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for df_name in tqdm(dfs_names):\n",
        "    for preproc_type in tqdm(['BinEncoding']):\n",
        "        temp_path = df_name + '/' + preproc_type + '/'\n",
        "        X = dfs[df_name].drop([dfs_targets[df_name]], axis=1)\n",
        "        y = dfs[df_name][dfs_targets[df_name]]\n",
        "        bin_edges, bins, bin_values = construct_bins(X[dfs_nf[df_name]], nbins)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
        "        X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(X_train, y_train, test_size=0.2, shuffle=False)\n",
        "        temp = []\n",
        "        final_res = defaultdict(list)\n",
        "        n_runs=15\n",
        "        silent=True,\n",
        "        glob_silent=True\n",
        "        best_metric = np.inf\n",
        "        best_r2 = np.inf\n",
        "        best_mae = np.inf\n",
        "        cat_len = len(dfs_cc[df_name])\n",
        "        seeds = np.random.randint(1, 100500, 15)\n",
        "        for i in range(n_runs):\n",
        "            if not silent:\n",
        "                print(f'Run {i+1}:')\n",
        "                print()\n",
        "            set_global_seed(seeds[i])\n",
        "            res_metrics = defaultdict(list)\n",
        "            X_train_t = torch.from_numpy(X_train_t.values).float()\n",
        "            y_train_t = torch.from_numpy(y_train_t.values.ravel()).float().unsqueeze(1)\n",
        "            X_test_t = torch.from_numpy(X_test_t.values).float()\n",
        "            y_test_t = torch.from_numpy(y_test_t.values.ravel()).float().unsqueeze(1)\n",
        "            X_test = torch.from_numpy(X_test.values).float()\n",
        "            y_test = torch.from_numpy(y_test.values.ravel()).float().unsqueeze(1)\n",
        "\n",
        "            train_ds = torch.utils.data.TensorDataset(X_train_t, y_train_t)\n",
        "            val_ds = torch.utils.data.TensorDataset(X_test_t, y_test_t)\n",
        "            test_ds = torch.utils.data.TensorDataset(X_test, y_test)\n",
        "            train_dataloader = torch.utils.data.DataLoader(train_ds, batch_size=256, shuffle=True)\n",
        "            val_dataloader = torch.utils.data.DataLoader(val_ds, batch_size=256, shuffle=True)\n",
        "            test_dataloader = torch.utils.data.DataLoader(test_ds, batch_size=256, shuffle=True)\n",
        "\n",
        "            writer_train = []\n",
        "            writer_val = []\n",
        "            writer_test = []\n",
        "  \n",
        "            metric_factory = MetricFactory()\n",
        "            preproc_params, preproc_name = get_preproc_params(df_name, preproc_type, tf, d_embedding)\n",
        "                \n",
        "                \n",
        "            preproc_params['tf'] = True\n",
        "            feature_tokenizer = FeatureTokenizer(len(dfs_nf[df_name]), dfs_cc[df_name], d_embedding, \n",
        "                                                     preproc_name, 'ARM', preproc_params, positional, tf)\n",
        "            transformer_config = get_default_transformer_config(n_blocks=3)\n",
        "            transformer_config['last_layer_query_idx'] = [-1]\n",
        "            transformer_config['kv_compression_ratio'] = None\n",
        "            transformer_config['kv_compression_sharing'] = None\n",
        "            transformer_config['d_out'] = 1\n",
        "            if preproc_name == 'Periodic':\n",
        "                transformer_config['d_token'] = 2 * d_embedding\n",
        "            else:\n",
        "                transformer_config['d_token'] = d_embedding\n",
        "            transformer = rtdl.Transformer(**transformer_config)\n",
        "            model = rtdl.FTTransformer(feature_tokenizer, transformer)\n",
        "            model.to(device)\n",
        "\n",
        "\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=5e-3, weight_decay=0)\n",
        "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=100, eta_min=1e-5)\n",
        "            criterion = torch.nn.MSELoss()\n",
        "            metric_rmse, metric_r2, metric_mae = train_ftt(100, model, train_dataloader, val_dataloader, test_dataloader, optimizer, None, criterion, writer_train,\n",
        "                            writer_val, writer_test, device, 20, silent, glob_silent)\n",
        "                \n",
        "            test_metrics = writer_test[-1][0]\n",
        "            test_loss = writer_test[-1][1]\n",
        "            for key, value in test_metrics.items():\n",
        "                res_metrics[key].append(value[0])\n",
        "            res_metrics['loss'].append(test_loss)\n",
        "            \n",
        "            for key, value in res_metrics.items():\n",
        "                final_res[key].append(np.mean(value))\n",
        "            s = 'run' + str(i + 1) + '.pickle'\n",
        "            with open(path + temp_path + s, 'wb') as f:\n",
        "                pickle.dump(res_metrics, f)\n",
        "    \n",
        "        ans = {}\n",
        "        for key, value in final_res.items():\n",
        "            ans[key] = float(np.mean(value))\n",
        "        \n",
        "        with open(path + temp_path + 'metrics.yml', 'w') as f:\n",
        "            ruamel.yaml.round_trip_dump(ans, f)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-18T23:11:17.266181Z",
          "iopub.execute_input": "2023-04-18T23:11:17.266553Z"
        },
        "trusted": true,
        "id": "OnX_RvB9tM8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f0OqMPattM8c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}